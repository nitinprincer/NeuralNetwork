{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Google API for Image Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Road 0.95081395\n",
      "Traffic sign 0.932612\n",
      "Lane 0.9286195\n",
      "Sign 0.9267741\n",
      "Signage 0.9219791\n",
      "Asphalt 0.87702805\n",
      "Highway 0.8670703\n",
      "Line 0.8286462\n",
      "Infrastructure 0.7639009\n",
      "Thoroughfare 0.731412\n"
     ]
    }
   ],
   "source": [
    "from base64 import b64encode\n",
    "\n",
    "import googleapiclient.discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Settings\n",
    "IMAGE_FILE = \"road_sign.jpg\"\n",
    "CREDENTIALS_FILE = \"credentials.json\"\n",
    "\n",
    "# Connect to the Google Cloud-ML Service\n",
    "credentials = GoogleCredentials.from_stream(CREDENTIALS_FILE)\n",
    "service = googleapiclient.discovery.build('vision', 'v1', credentials=credentials)\n",
    "\n",
    "# Read file and convert it to a base64 encoding\n",
    "with open(IMAGE_FILE, \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "    encoded_image_data = b64encode(image_data).decode('UTF-8')\n",
    "\n",
    "# Create the request object for the Google Vision API\n",
    "batch_request = [{\n",
    "    'image': {\n",
    "        'content': encoded_image_data\n",
    "    },\n",
    "    'features': [\n",
    "        {\n",
    "            'type': 'LABEL_DETECTION'\n",
    "        }\n",
    "    ]\n",
    "}]\n",
    "request = service.images().annotate(body={'requests': batch_request})\n",
    "\n",
    "# Send the request to Google\n",
    "response = request.execute()\n",
    "\n",
    "# Check for errors\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "\n",
    "# Print the results\n",
    "labels = response['responses'][0]['labelAnnotations']\n",
    "\n",
    "for label in labels:\n",
    "    print(label['description'], label['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Google API for Text Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEATRICE\n",
      "I pray you, is Signior Mountanto returned from the\n",
      "wars or no?\n",
      "Messenger\n",
      "I know none of that name, lady: there was none such\n",
      "in the army of any sort,\n",
      "LEONATO\n",
      "What is he that you ask for, niece?\n",
      "HERO\n",
      "My cousin means Signior Benedick of Padua.\n",
      "Messenger\n",
      "O, he's returned; and as pleasant as ever he was\n",
      "BEATRICE\n",
      "He set up his bills here in Messina and challenged\n",
      "Cupid at the flight; and my uncle's fool, reading\n",
      "the challenge, subscribed for Cupid, and challenged\n",
      "him at the bird-bolt. I pray you, how many hath he\n",
      "killed and eaten in these wars? But how many hath\n",
      "he killed? for indeed I promised to eat all of his killing\n",
      "\n",
      "{'vertices': [{'x': 16, 'y': 9}, {'x': 794, 'y': 9}, {'x': 794, 'y': 1038}, {'x': 16, 'y': 1038}]}\n"
     ]
    }
   ],
   "source": [
    "from base64 import b64encode\n",
    "\n",
    "import googleapiclient.discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Change this values to match your project\n",
    "IMAGE_FILE = \"text.png\"\n",
    "CREDENTIALS_FILE = \"credentials.json\"\n",
    "\n",
    "# Connect to the Google Cloud-ML Service\n",
    "credentials = GoogleCredentials.from_stream(CREDENTIALS_FILE)\n",
    "service = googleapiclient.discovery.build('vision', 'v1', credentials=credentials)\n",
    "\n",
    "# Read file and convert it to a base64 encoding\n",
    "with open(IMAGE_FILE, \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "    encoded_image_data = b64encode(image_data).decode('UTF-8')\n",
    "\n",
    "# Create the request object for the Google Vision API\n",
    "batch_request = [{\n",
    "    'image': {\n",
    "        'content': encoded_image_data\n",
    "    },\n",
    "    'features': [\n",
    "        {\n",
    "            'type': 'TEXT_DETECTION'\n",
    "        }\n",
    "    ]\n",
    "}]\n",
    "request = service.images().annotate(body={'requests': batch_request})\n",
    "\n",
    "# Send the request to Google\n",
    "response = request.execute()\n",
    "\n",
    "# Check for errors\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "\n",
    "# Print the results\n",
    "extracted_texts = response['responses'][0]['textAnnotations']\n",
    "\n",
    "# Print the first piece of text found in the image\n",
    "extracted_text = extracted_texts[0]\n",
    "print(extracted_text['description'])\n",
    "\n",
    "# Print the location where the text was detected\n",
    "print(extracted_text['boundingPoly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
